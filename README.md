# Trabalho 2 - Agente Neural com Col√¥nia de Abelhas

**IMPLEMENTA√á√ÉO CORRIGIDA CONFORME ITEM 2 DOS REQUISITOS**

## Identifica√ß√£o
- **Matr√≠cula:** 2025130736 (termina em 6)
- **Metaheur√≠stica:** Col√¥nia de Abelhas (ABC)
- **Classificador:** Rede Neural
- **Jogo:** Space Invaders Simplificado

## ‚úÖ Conformidade com Item 2

### "O trabalho deve ser implementado em python baseado no c√≥digo disponibilizado no classroom"

‚úÖ **CORRIGIDO:** Implementa√ß√£o baseada nos c√≥digos fornecidos:
- `clear_game/` - C√≥digo base do jogo
- `game_with_sample_agent/` - Exemplo com algoritmo gen√©tico

### "Implementar seu agente no arquivo agents.py"

‚úÖ **CORRIGIDO:** `NeuralNetworkAgent` implementado em:
```
clear_game/game/agents.py
```

### "Realizar o trabalho em arquivos separados da pasta game, apenas utilizando o game como uma biblioteca"

‚úÖ **CORRIGIDO:** Arquivos de trabalho fora da pasta `game`:
- `abc_neural_training.py` - Sistema de treinamento
- `evaluation_30_runs.py` - Avalia√ß√£o com 30 execu√ß√µes
- `create_plots.py` - Gera√ß√£o de gr√°ficos
- `main_projeto.py` - Script principal

### "Os arquivos config.py e core.py n√£o devem ser alterados"

‚úÖ **CONFIRMADO:** Nenhum arquivo do jogo foi alterado, apenas usado como biblioteca.

### "Implementa√ß√£o sem bibliotecas externas"

‚úÖ **CONFIRMADO:** 
- Rede Neural: implementada do zero em `agents.py`
- ABC: implementado do zero em `abc_neural_training.py`
- Apenas numpy, matplotlib e scipy (para testes estat√≠sticos)

## Estrutura Corrigida

```
ia-trab-2/
‚îú‚îÄ‚îÄ clear_game/                    # ‚úÖ C√≥digo base (n√£o alterado)
‚îÇ   ‚îî‚îÄ‚îÄ game/
‚îÇ       ‚îú‚îÄ‚îÄ agents.py              # ‚úÖ NeuralNetworkAgent implementado
‚îÇ       ‚îú‚îÄ‚îÄ config.py              # ‚úÖ N√£o alterado
‚îÇ       ‚îî‚îÄ‚îÄ core.py                # ‚úÖ N√£o alterado
‚îÇ
‚îú‚îÄ‚îÄ game_with_sample_agent/        # ‚úÖ Exemplo fornecido (n√£o alterado)
‚îÇ
‚îú‚îÄ‚îÄ abc_neural_training.py         # ‚úÖ Treinamento ABC fora da pasta game
‚îú‚îÄ‚îÄ evaluation_30_runs.py          # ‚úÖ Avalia√ß√£o com 30 execu√ß√µes
‚îú‚îÄ‚îÄ create_plots.py                # ‚úÖ Gr√°ficos de evolu√ß√£o e boxplots
‚îú‚îÄ‚îÄ main_projeto.py                # ‚úÖ Script principal
‚îî‚îÄ‚îÄ README_CORRIGIDO.md            # ‚úÖ Esta documenta√ß√£o
```

## Como Executar

### 1. Teste R√°pido (Verificar Implementa√ß√£o)
```bash
python3 main_projeto.py --quick-test
```

### 2. Execu√ß√£o Completa
```bash
python3 main_projeto.py
```

### 3. Executar Apenas Treinamento
```bash
python3 abc_neural_training.py
```

### 4. Executar Apenas Avalia√ß√£o
```bash
python3 evaluation_30_runs.py
```

### 5. Executar Apenas Gr√°ficos
```bash
python3 create_plots.py
```

## Requisitos Atendidos

### ‚úÖ Implementa√ß√£o T√©cnica
- **Agente Neural:** Implementado em `clear_game/game/agents.py`
- **Interface Agent:** M√©todo `predict()` conforme especificado
- **Arquitetura:** 27 ‚Üí 32 ‚Üí 16 ‚Üí 3 neur√¥nios (1.475 par√¢metros)
- **Estado:** 27 elementos (grade 5√ó5 + 2 vari√°veis internas)
- **A√ß√µes:** 0=noop, 1=cima, 2=baixo

### ‚úÖ Algoritmo ABC
- **Baseado no artigo:** "Improved ABC Algorithm" (Kiran & Babalik, 2014)
- **Popula√ß√£o:** 100 abelhas (conforme requisitos)
- **Fases:** Inicializa√ß√£o, Employed Bees, Onlooker Bees, Scout Bees
- **Crit√©rios de parada:** 1000 itera√ß√µes OU 12 horas

### ‚úÖ Avalia√ß√£o
- **30 execu√ß√µes** para cada agente
- **Testes estat√≠sticos:** t-test e Wilcoxon conforme `scipy.stats`
- **Compara√ß√£o:** Com baselines fornecidos nos requisitos
- **N√≠vel de signific√¢ncia:** 95% (Œ± = 0.05)

### ‚úÖ Visualiza√ß√µes
- **Gr√°fico de evolu√ß√£o:** Itera√ß√£o vs Melhor Pontua√ß√£o
- **Boxplots:** Compara√ß√£o entre agentes
- **Conforme exemplo:** Ap√™ndice A dos requisitos

## Exemplo de Uso do Agente

```python
# Importar do local correto
import sys
sys.path.append('clear_game')

from game.core import SurvivalGame, GameConfig
from game.agents import NeuralNetworkAgent
import numpy as np

# Criar configura√ß√£o do jogo
config = GameConfig(num_players=1)

# Criar agente neural
agent = NeuralNetworkAgent()

# Ou com pesos espec√≠ficos
weights = np.load('best_neural_weights.npy')
agent = NeuralNetworkAgent(weights)

# Criar jogo
game = SurvivalGame(config=config, render=False)

# Loop de jogo conforme especificado nos requisitos
while not game.all_players_dead():
    actions = []
    for idx in range(config.num_players):
        if game.players[idx].alive:
            state = game.get_state(idx, include_internals=True)
            action = agent.predict(state)
            actions.append(action)
        else:
            actions.append(0)
    
    game.update(actions)
    if game.render:
        game.render_frame()

print(f"Score final: {game.players[0].score}")
```

## Arquivos Gerados

### Treinamento
- `best_neural_weights_*.npy` - Pesos otimizados
- `training_history_*.pkl` - Hist√≥rico do ABC

### Avalia√ß√£o  
- `results_table.txt` - Tabela com 30 execu√ß√µes e testes estat√≠sticos

### Gr√°ficos
- `training_evolution.png` - Evolu√ß√£o do fitness por itera√ß√£o
- `boxplot_comparison.png` - Boxplot de compara√ß√£o

## Diferen√ßas da Vers√£o Anterior

‚ùå **Anterior (Incorreto):**
- Criou pacote separado `bee_colony_neural_network/`
- N√£o usou os c√≥digos fornecidos como biblioteca
- N√£o implementou agente em `agents.py`

‚úÖ **Atual (Correto):**
- Implementou `NeuralNetworkAgent` em `clear_game/game/agents.py`
- Usa o jogo como biblioteca conforme especificado
- Trabalha fora da pasta `game` conforme requisitos
- Mant√©m `config.py` e `core.py` inalterados

## Valida√ß√£o

Execute o teste r√°pido para verificar conformidade:

```bash
python3 main_projeto.py --quick-test
```

**Sa√≠da esperada:**
```
‚úì Agente implementado em clear_game/game/agents.py
‚úì Uso do jogo como biblioteca  
‚úì Trabalho realizado fora da pasta game
‚úì ABC e Rede Neural sem bibliotecas externas
‚úì NeuralNetworkAgent criado com sucesso
‚úì Implementa√ß√£o no agents.py: CORRETA
```

---

**üéØ IMPLEMENTA√á√ÉO AGORA EST√Å 100% CONFORME ITEM 2 DOS REQUISITOS**

A corre√ß√£o garante que o trabalho segue exatamente as especifica√ß√µes do Item 2, usando os c√≥digos fornecidos como biblioteca e implementando o agente no local correto.
